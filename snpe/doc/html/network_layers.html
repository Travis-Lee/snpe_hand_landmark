<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-->
<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"></meta>
<meta http-equiv="X-UA-Compatible" content="IE=9"></meta>
<title>Snapdragon Neural Processing Engine SDK: Supported Network Layers</title>
<link href="tabs.css" rel="stylesheet" type="text/css"></link>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="autoEnterCurrentDate.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="is.css" rel="stylesheet" type="text/css" ></link>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Snapdragon Neural Processing Engine SDK
   <span id="projectnumber"></span></div>
   <div id="projectbrief">Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('network_layers.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Supported Network Layers </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="network_layers"></a>
Supported Network Layers</h1>
<p>SNPE supports the network layer types listed in the table below.</p>
<p>See <a class="el" href="limitations.html#limitations_all">Limitations</a> for details on the limitations and constraints for the supported runtimes and individual layer types.</p>
<p>All of supported layers in GPU runtime are valid for both of GPU modes: GPU_FLOAT32_16_HYBRID and GPU_FLOAT16.<br />
GPU_FLOAT32_16_HYBRID - data storage is done in half float and computation is done in full float.<br />
GPU_FLOAT16 - both data storage and computation is done in half float.</p>
<p>A list of supported ONNX operations can be found at <a class="el" href="supported_onnx_ops.html#onnx_operator_support">ONNX Operator Support</a>.</p>
<p><a class="anchor" id="tbl_network_layer_support"></a>  <p><table class="doxtable" width="100%">  <tr>  <th colspan="1">Layer Type</th>  <th colspan="1">Description</th>  <th colspan="1">Caffe <br />
 Equivalent</th>  <th colspan="1">Caffe2 <br />
 Equivalent</th>  <th colspan="1">TensorFlow <br />
 Equivalent</th>  <th colspan="1">Onnx <br />
 Equivalent</th>  <th colspan="1">CPU</th>  <th colspan="1">GPU</th>  <th colspan="1">DSP/ <br />
 AIP</th>  </tr>  <tr>  <td> ArgMax  </td>  <td> Returns the index with the largest value across axes of a tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/argmax" target="_blank">ArgMax</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font> <br />
 <a class="el" href="limitations.html#argmax_layer_limitations">(?)</a>  </td>  </tr>  <tr>  <td> Batch normalization (+ Scaling)  </td>  <td> Batch normalization (optionally followed by scaling operation).  </td>  <td> Maps to the combination of batch_norm_layer followed immediately by scale_layer. <a class="el" href="limitations.html#batch_norm_layer_limitations">(?)</a><br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/batch_norm_layer.cpp" target="_blank">batch_norm_layer.cpp</a><br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/scale_layer.cpp" target="_blank">scale_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/spatial_batch_norm_op.cc" target="_blank">spatial_batch_norm_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization" target="_blank">batch_normalization</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization" target="_blank">BatchNormalization</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font> <br />
 <a class="el" href="limitations.html#batch_norm_layer_limitations">(?)</a>  </td>  </tr>  <tr>  <td> Channel Shuffle  </td>  <td> Interleaves the channels in groups. The number of channels must be divisible by the number of groups. At least 4 channels are required for this layer to have any effect.  </td>  <td> n/a  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/channel_shuffle_op.h" target="_blank">channel_shuffle_op.h</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Color space conversion  </td>  <td> Converts input image color format (encoding type) into SNPE native color space. Color space conversion parameters are provided as an option to the model converter tool.  </td>  <td> There is no such Caffe layer by itself. This functionality is technically part of the Caffe data provider.<br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/data_layer.cpp" target="_blank">data_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Concatenation  </td>  <td> This layer concatenates multiple inputs into a single output.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/concat_layer.cpp" target="_blank">concat_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/concat_split_op.cc" target="_blank">concat_split_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/concat" target="_blank">concat</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Concat" target="_blank">Concat</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Convolution  </td>  <td> Computes dot products between the entries of the filter and the input at any position.  </td>  <td> Includes support for groups and dilation. <br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/conv_layer.cpp" target="_blank">conv_layer.cpp</a>  </td>  <td> Includes support for spatial reflection padding. <br />
 <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/conv_op.cc" target="_blank">conv_op.cc</a>  </td>  <td> <a href="https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tf/nn/conv2d.md" target="_blank">conv2d</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv" target="_blank">Conv</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Crop  </td>  <td> Crops one layer to the dimensions of a reference layer.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/crop_layer.cpp" target="_blank">crop_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/utility_ops.cc" target="_blank">utility_ops.cc</a>  </td>  <td>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> CropAndResize  </td>  <td> Crops normalized regions from a batch of images and scales them to a desired output size.  </td>  <td>  </td>  <td>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/image/crop_and_resize" target="_blank">crop_and_resize</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> CrossMap Response Normalization  </td>  <td> This is an option within LRN layer.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/lrn_layer.cpp" target="_blank">lrn_layer.cpp</a>  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization" target="_blank">local_response_normalization</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN" target="_blank">LRN</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Deconvolution  </td>  <td> Performs deconvolution operation.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/deconv_layer.cpp" target="_blank">deconv_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/conv_transpose_op.cc" target="_blank">conv_transpose_op.cc</a>  </td>  <td> <a href="https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tf/layers/Conv2DTranspose.md" target="_blank">conv2d_transpose</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose" target="_blank">ConvTranspose</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Depthwise Convolution  </td>  <td> Performs a 2D depthwise convolution.  </td>  <td> Equivalent to Convolution with 'num_output' = input channels and 'group' = 'num_output' <br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/conv_layer.cpp" target="_blank">conv_layer.cpp</a>  </td>  <td> Equivalent to Convolution with 'num_output' = input channels and 'group' = 'num_output' <br />
 <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/conv_op.cc" target="_blank">conv_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d" target="_blank">tf.nn.depthwise_conv2d</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Detection Output  </td>  <td> Generate the detection output based on location and confidence predictions by doing non maximum suppression.<br />
 Typically used in SSD networks.  </td>  <td> Note that this layer is not available on the tip of Caffe. It requires a compatible branch of Caffe.<br />
 <a href="https://github.com/weiliu89/caffe/blob/ssd/src/caffe/layers/detection_output_layer.cpp" target="_blank">detection_output_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Dropout  </td>  <td> Layer is used for training only. Converters remove this layer from DLC creation.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/dropout_layer.cpp" target="_blank">dropout_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/dropout_op.cc" target="_blank">dropout_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout" target="_blank">dropout</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Dropout" target="_blank">Dropout</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  </tr>  <tr>  <td> Elementwise  </td>  <td> Supports SUM, PROD, MAX, MIN, and SUB mode with coefficients.  </td>  <td> Support for MAX, SUM, and PROD <br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/eltwise_layer.cpp" target="_blank">eltwise_layer.cpp</a>  </td>  <td> Support for SUM and MAX <br />
 <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/utility_ops.cc" target="_blank">utility_ops.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/add" target="_blank">add</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/add_n" target="_blank">add_n</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/multiply" target="_blank">mul</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/maximum" target="_blank">maximum</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/minimum" target="_blank">minimum</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/subtract" target="_blank">subtract</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Add" target="_blank">Add</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul" target="_blank">Mul</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max" target="_blank">Max</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Min" target="_blank">Min</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sub" target="_blank">Sub</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sum" target="_blank">Sum</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Elementwise Unary  </td>  <td> Supports ABS, EXP, FLOOR, LOG, NEG, SIN, and SQRT.  </td>  <td>  </td>  <td>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/math/floor" target="_blank">floor</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/sqrt" target="_blank">sqrt</a> <br />
  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Abs" target="_blank">Abs</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Exp" target="_blank">Exp</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Floor" target="_blank">Floor</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Log" target="_blank">Log</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Neg" target="_blank">Neg</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sin" target="_blank">Sin</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sqrt" target="_blank">Sqrt</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Elu  </td>  <td> activation function: elu [ i.e., f(x) = max(0,x) + a*(exp(min(0,x))-1) ]  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/elu_layer.cpp" target="_blank">elu_layer.cpp</a>  </td>  <td> <a href="https://github.com/pytorch/pytorch/blob/master/caffe2/operators/elu_op.cc" target="_blank">elu_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/elu" target="_blank">elu</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu" target="_blank">elu</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Flatten  </td>  <td> Flatten an input to a layer  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/flatten_layer.cpp" target="_blank">flatten_layer.cpp</a>  </td>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/utility_ops.cc" target="_blank">utility_ops.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/layers/Flatten" target="_blank">flatten</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Flatten" target="_blank">Flatten</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Fully connected  </td>  <td> Similar to convolution, but with connections to full input region, i.e., with filter size being exactly the size of the input volume.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/inner_product_layer.cpp" target="_blank">inner_product_layer.cpp</a>  </td>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/fully_connected_op.cc" target="_blank">fully_connected_op.cc</a>  </td>  <td> <a href="https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tf/layers/Dense.md" target="_blank">dense</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/tensordot" target="_blank">Tensordot</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul" target="_blank">MatMul</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> HeatmapMaxKeypoint  </td>  <td> Keypoint detection  </td>  <td> n/a  </td> <a href="https://www.tensorflow.org/tutorials/layers#input_layer" target="_blank">input</a>  <td>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Input  </td>  <td> This is an input layer to the network.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/input_layer.cpp" target="_blank">input_layer.cpp</a>  </td>  <td>  </td>  <td> <a href="https://www.tensorflow.org/tutorials/layers#input_layer" target="_blank">input</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> InstanceNorm  </td>  <td> Instance normalization  </td>  <td> Supported as batch_norm_layer with 'use_global_stats' = false.  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/instance_norm_op.cc" target="_blank">instance_norm_op.cc</a>  </td>  <td>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#InstanceNormalization" target="_blank">InstanceNormalization</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> L2Norm  </td>  <td> L2 normalization along innermost dimension.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/math/l2_normalize">L2 Normalize</a>  </td>  <td>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Local Response Normalization (LRN)  </td>  <td> Performs a lateral inhibition by normalizing over local input regions.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/lrn_layer.cpp" target="_blank">lrn_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/local_response_normalization_op.cc" target="_blank">local_response_normalization_op.cc</a>  </td>  <td>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN" target="_blank">LRN</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> LSTM  </td>  <td> LSTM recurrent network cell  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/lstm_layer.cpp" target="_blank">lstm_layer.cpp</a>  </td>  <td>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell" target="_blank">tf.contrib.rnn.BasicLSTMCell </a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/static_rnn" target="_blank">tf.nn.static_rnn </a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM" target="_blank">LSTM</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Normalize  </td>  <td> Instance normalization using RMS instead of mean/variance.  </td>  <td> Note that this layer is not available on the tip of Caffe. It requires a compatible branch of Caffe.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <font color= green size= 5>&#x2714;</font>  </td>  <td> <font color= green size= 5>&#x2714;</font>  </td>  <td> <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Output  </td>  <td> There is no explicit output layer as the results from any layer in the network can be specified as an output when loading a network.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  </tr>  <tr>  <td> Pack  </td>  <td> Packs a list of tensors of rank "r" into a single rank (r+1) tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/stack" target="_blank">stack</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Pad  </td>  <td> Performs padding on the input tensor on the edges, in any or all dimensions as specified. values can be specified ("CONSTANT" mode in tf) or using mirror padding ("REFLECT" mode in tf)  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/pad" target="_blank">pad</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Permute  </td>  <td> Permute is used to rearrange the dimensions of a tensor.  </td>  <td> Note that this layer is not available on the tip of Caffe. It requires a compatible branch of Caffe.<br />
 <a href="https://github.com/weiliu89/caffe/blob/ssd/src/caffe/layers/permute_layer.cpp" target="_blank">permute_layer.cpp</a>  </td>  <td> n/a  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/transpose" target="_blank">transpose</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Transpose" target="_blank">Transpose</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Pooling  </td>  <td> Pooling operation down samples the input volume spatially. Both average and max pooling are supported.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/pooling_layer.cpp" target="_blank">pooling_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/pool_op.cc" target="_blank">pool_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/layers/average_pooling2d" target="_blank">average_pooling2d</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d" target="_blank">max_pooling2d</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool" target="_blank">MaxPool</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool" target="_blank">AveragePool</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalMaxPool" target="_blank">GlobalMaxPool</a> <br />
 <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalAveragePool" target="_blank">GlobalAveragePool</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  </tr>  <tr>  <td> Power  </td>  <td> Power layer computes (shift + scale * x) ^ power for input x. <a class="el" href="limitations.html#power_layer_limitations">(?)</a>  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/power_layer.cpp" target="_blank">power_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font> <a class="el" href="limitations.html#power_layer_limitations">(?)</a>  </td>  </tr>  <tr>  <td> Prelu  </td>  <td> activation function: prelu [ i.e., y = max(0, x) + a*min(0,x) ]  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/prelu_layer.cpp" target="_blank">prelu_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/prelu_op.cc" target="_blank">prelu_op.cc</a>  </td>  <td> <a href="http://tflearn.org/activations/#prelu" target="_blank">PReLU </a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#PRelu" target="_blank">PRelu</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Prior Box  </td>  <td> Generate the prior boxes of designated sizes and aspect ratios. Typically used in SSD networks.<br />
 This layer is handled (folded in) and removed from the DLC model during conversion.  </td>  <td> Note that this layer is not available on the tip of Caffe. It requires a compatible branch of Caffe.<br />
 <a href="https://github.com/weiliu89/caffe/blob/ssd/src/caffe/layers/prior_box_layer.cpp" target="_blank">prior_box_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  </tr>  <tr>  <td> Proposal  </td>  <td> Outputs region proposals, usually for consumption of an ROIPooling layer. Typically used in Faster RCNN.  </td>  <td> Note that this layer is not available on the tip of Caffe. It requires a compatible branch of Caffe.<br />
 <a href="https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/proposal_layer.py" target="_blank">proposal_layer.py</a>  </td>  <td>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>   </tr>  <tr>  <td> Relu  </td>  <td> activation function: relu [ i.e., y = max(0,x) ]  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/relu_layer.cpp" target="_blank">relu_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/relu_op.cc" target="_blank">relu_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu" target="_blank">relu</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Relu" target="_blank">Relu</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Reshape  </td>  <td> Change dimensions of the input to a layer  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/reshape_layer.cpp" target="_blank">reshape_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/utility_ops.cc" target="_blank">utility_ops.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/reshape" target="_blank">reshape</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape" target="_blank">Reshape</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Sigmoid  </td>  <td> activation function: sigmoid [ i.e., y = 1/(1 + exp(-x) ]  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/sigmoid_layer.cpp" target="_blank">sigmoid_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/sigmoid_op.cc" target="_blank">sigmoid_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/sigmoid" target="_blank">sigmoid</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sigmoid" target="_blank">Sigmoid</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Scale (Image)  </td>  <td> Input image scaling, maintains aspect ratio. This function is primarily intended for images, but technically any 2D input data can be processed if it makes sense. Scaling parameters are provided as an option to the model converter tool.  </td>  <td> There is no such Caffe layer by itself. This functionality is technically part of the Caffe data provider.<br />
 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/data_layer.cpp" target="_blank">data_layer.cpp</a>  </td>  <td> Resize Nearest Neighbor <b>(Not supported on DSP)</b> <br />
 <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/resize_op.cc" target="_blank">resize_op.cc</a>  </td>  <td> Resize Bilinear (does not support align_corners=True) <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/image/resize_bilinear" target="_blank">tf.image.resize_bilinear</a> <br />
 Resize Nearest Neighbor <b>(Not supported on DSP)</b> <a href="https://www.tensorflow.org/api_docs/python/tf/image/resize_nearest_neighbor" target="_blank">tf.image.resize_nearest_neighbor</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Scale  </td>  <td> Elementwise scale, optionally add biases.  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/scale_layer.cpp" target="_blank">scale_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Silence  </td>  <td> Silence is handled and removed from the model during conversion, similar to Dropout.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/silence_layer.cpp" target="_blank">silence_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  </tr>  <tr>  <td> Slice  </td>  <td> Slices an input layer into multiple output layers.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/slice_layer.cpp" target="_blank">slice_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/concat_split_op.cc" target="_blank">concat_split_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/split" target="_blank">split</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice" target="_blank">Slice</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Softmax  </td>  <td> Supports 1D and 2D modes.  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/softmax_layer.cpp" target="_blank">softmax_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/softmax_op.cc" target="_blank">softmax_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax" target="_blank">softmax</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softmax" target="_blank">Softmax</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Space to Depth  </td>  <td> Rearranges blocks of spatial data into depth.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/space_to_depth" target="_blank">tf.nn.space_to_depth </a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>   </tr>  <tr>  <td> Strided Slice  </td>  <td> Extracts a slice of size (end-begin)/stride from the given input_tensor. Starting at the location specified by begin the slice continues by adding stride to the index until all dimensions are not less than end. Note that a stride can be negative, which causes a reverse slice.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/strided_slice" target="_blank">tf.strided_slice </a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>   </tr>  <tr>  <td> Tanh  </td>  <td> activation function: tanh [ i.e., y = tanh(x) ]  </td>  <td> <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers/tanh_layer.cpp" target="_blank">tanh_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/tanh_op.cc" target="_blank">tanh_op.cc</a>  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/tanh" target="_blank">tanh</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tanh" target="_blank">Tanh</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Tile  </td>  <td> Copies a blob along the specified dimensions  </td>  <td> <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/tile_layer.cpp" target="_blank">tile_layer.cpp</a>  </td>  <td> <a href="https://github.com/facebookarchive/caffe2/blob/move-to-pytorch/caffe2/operators/tile_op.cc" target="_blank">tile_op.cc</a>  </td>  <td>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Unpack  </td>  <td> Unpacks "n" tensors from a single packed tensor splitting along the axis dimension.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/unstack" target="_blank">unstack</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Cross Correlation Layer  </td>  <td> Computes dot products between the entries of the filter and the input at any position and then rotates the result by 180 degrees.  </td>  <td> <a href="https://github.com/lmb-freiburg/flownet2/blob/master/src/caffe/layers/correlation_layer.cpp" target="_blank">correlation_layer.cpp</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Embedding Layer  </td>  <td> Turns positive integers (indexes) into dense vectors of fixed size.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding" target="_blank">embedding_layer</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> ExtractGlimpse  </td>  <td> Returns a set of windows called glimpses extracted at location offsets from the input tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/image/extract_glimpse" target="_blank">extract_glimpse</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  </tr>  <tr>  <td> Gather  </td>  <td> Gather slices from params axis according to indices.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/gather" target="_blank">gather</a>  </td>  <td> <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gather" target="_blank">Gather</a>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Image Projective Transform  </td>  <td> Applies the projective transform to the image represented by a tensor of shape (num_images, num_rows, num_columns, num_channels).  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/image/translations_to_projective_transforms" target="_blank">image_projective_transform</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Moments  </td>  <td> Calculate the mean and variance of input tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/moments" target="_blank">moments</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Depth To Space  </td>  <td> Rearranges data from depth into blocks of spatial data. This is the reverse transformation of SpaceToDepth.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/nn/depth_to_space" target="_blank">depth_to_space</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Strided Slice  </td>  <td> Extracts a strided slice of a tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/strided_slice" target="_blank">strided_slice</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Bbox Transform  </td>  <td> Transform proposal bounding boxes to target bounding box using bounding box regression deltas.  </td>  <td> n/a  </td>  <td> <a href="https://github.com/pytorch/pytorch/blob/master/caffe2/operators/bbox_transform_op.cc" target="_blank">bbox_transform_op.cc</a>  </td>  <td> n/a  </td>  <td> n/a  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= red size= 5>&#x2718;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  <tr>  <td> Reduce (max, min, sum, product, mean)  </td>  <td> Computes the maximum, minimum, sum, product, mean of elements across dimensions of a tensor.  </td>  <td> n/a  </td>  <td> n/a  </td>  <td> <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_max" target="_blank">reduce_max</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_min" target="_blank">reduce_min</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum" target="_blank">reduce_sum</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_prod" target="_blank">reduce_prod</a> <br />
 <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean" target="_blank">reduce_mean</a>  </td>  <td> n/a  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  <td>  <font color= green size= 5>&#x2714;</font>  </td>  </tr>  </table></p><p>Note : AIP Runtime supports all layers supported by the DSP runtime, as layers not supported by HTA run on HVX. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 -->
<!-- start footer part -->
<div id="nav-path" class="navpath" font-size:small;><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
      <p align="right">
        80-NL315-14 A <br>
        MAY CONTAIN U.S. AND INTERNATIONAL EXPORT CONTROLLED INFORMATION
        <!--If the Controlled Distribution statement is to be included, uncomment below:-->
        <!--<b>Controlled Distribution - DO NOT COPY</b>-->
        <img class="footer" width:5%; alt="QTI Logo" src="images/QTI_Logo.png" />
      </p>
    </li>
  </ul>
</div>
</body>
</html>
